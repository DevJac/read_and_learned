#+STARTUP: latexpreview
* What are vectors?
There are a few different interpretations of what a vector is:

- a magnitude and a direction
- a tuple of numbers that form a type
- anything where there is a sensible definition of adding two vectors and multiplying by a scalar
** Types vs Vectors
An xy-coordinate and a tuple of ~(age, weight)~ are essentially the same. The operations that work on one will also work on the other.
** Tuple/point notation vs Vector notation
Where we might write a tuple or a vector as ~(1, 2)~ traditionally, we would write a vertical column matrix in linear algebra:

\begin{equation*}
\begin{bmatrix}
1 \\
2
\end{bmatrix}
\end{equation*}
* Basic vector operations
** Vector addition
\begin{equation*}
\begin{bmatrix}
1 \\
2
\end{bmatrix}
+
\begin{bmatrix}
3 \\
4
\end{bmatrix}
=
\begin{bmatrix}
1 + 3 \\
2 + 4
\end{bmatrix}
=
\begin{bmatrix}
4 \\
6
\end{bmatrix}
\end{equation*}

A vector must contain values with units (types) that can be combined (added) in a sensible way.
** Vector scalar multiplication
\begin{equation*}
3
\begin{bmatrix}
1 \\
2
\end{bmatrix}
=
\begin{bmatrix}
3 \times 1 \\
3 \times 2
\end{bmatrix}
=
\begin{bmatrix}
3 \\
6
\end{bmatrix}
\end{equation*}
** Scaling unit vectors
The values in a column matrix scale "units" or "basis vectors". Notice the basic operations of addition and scalar multiplication in this single simple matrix.

\begin{equation*}
\begin{bmatrix}
1 \\
2
\end{bmatrix}
=
\begin{bmatrix}
1 \times \hat{i} \\
2 \times \hat{j}
\end{bmatrix}
=
1 \times \hat{i} + 2 \times \hat{j}
\end{equation*}
** Linear combinations
\begin{equation*}
a \times \hat{i} + b \times \hat{j}
\end{equation*}

Above is a "linear combination of $\hat{i}$ and $\hat{j}$". Notice, again, the basic operations of addition and scalar multiplication.
* Spans
The "span" of a set of vectors is the set of all possible linear combinations of those vectors.

"Basis vectors" can be though of as your building blocks. You can add the blocks, and you can scale the blocks. The "span" is the set of all vectors you could possibly build from your basis vectors using only addition and scalar multiplication.
** Linearly independent vectors
A set of vectors is said to be "linearly independent" if no vector can be expressed as a linear combination of the other vectors.

In other words, each vector brings something new (unique) to the table. Removing any of the vectors would reduce the span of the set.
* Matrix multiplication
\begin{equation}
\begin{bmatrix}
a & b \\
c & d
\end{bmatrix}
\begin{bmatrix}
x \\
y
\end{bmatrix}
=
x
\begin{bmatrix}
a \\
c
\end{bmatrix}
+
y
\begin{bmatrix}
b \\
d
\end{bmatrix}
=
\begin{bmatrix}
ax + by \\
cx + dy
\end{bmatrix}
\end{equation}

This is possibly the most important equation in linear algebra.

To understand it, remember that:

\begin{equation*}
\begin{bmatrix}
x \\
y
\end{bmatrix}
=
x \times \hat{i} + y \times \hat{j}
=
x \hat{i} + y \hat{j}
=
x
\begin{bmatrix}
1 \\
0
\end{bmatrix}
+
y
\begin{bmatrix}
0 \\
1
\end{bmatrix}
\end{equation*}

Because of the way matrix multiplication is defined, the above matrix multiplication will change the basis vectors such that:

\begin{equation*}
\hat{i}
\text{ becomes }
\begin{bmatrix}
a \\
c
\end{bmatrix}
\text{ and }
\hat{j}
\text{ becomes }
\begin{bmatrix}
b \\
d
\end{bmatrix}
\end{equation*}

And thus we arive back at the original formula, we have gone full circle.
** Order of matrices in matrix multiplication
The first matrix contains the new basis vectors. The order implies that a new basis is being applied to the second matrix.
* A matrix represents a linear transformation of space
All matrices represent linear transformations of space.
** TODO What about non-square matrices?
What does it mean for a non-square matrix to be the basis in matrix multiplication?
